---
layout: post
comments: true
categories: 机器学习
---

在分类任务中，模型的极大似然函数（Maximum Likelihood Estimation, MLE）通过以下步骤定义：

---

### **1. 问题设定**
假设分类任务有K个类别，给定训练数据集$\{(x_i, y_i)\}_{i=1}^N$，其中：
- $x_i$ 为输入特征。
- $y_i$ 为真实标签（离散值，如 one-hot 编码形式）。

模型的目标是输出每个类别的概率分布 $Q(y\\|x; \theta)$，其中$\theta$为模型参数。

---

### **2. 似然函数的定义**
#### **(1) 单样本的似然**
对于单个样本$(x_i, y_i)$，模型预测其为真实类别 $y_i$ 的概率为：

$$ Q(y_i | x_i; \theta). $$

#### **(2) 全数据集的联合似然**
假设样本独立同分布（i.i.d.），数据集的联合似然函数为各样本似然的乘积：

$$ \mathcal{L}(\theta) = \prod_{i=1}^N Q(y_i | x_i; \theta). $$

---

### **3. 极大似然估计的目标**
通过调整参数  $\theta$，最大化联合似然函数：

$$ \theta^* = \arg\max_{\theta} \mathcal{L}(\theta). $$

---

### **4. 对数似然函数**
为简化计算，取对数将乘积转为求和：

$$ \log \mathcal{L}(\theta) = \sum_{i=1}^N \log Q(y_i | x_i; \theta). $$

最大化对数似然等价于最小化负对数似然（Negative Log-Likelihood, NLL）：

$$ \text{NLL} = -\sum_{i=1}^N \log Q(y_i | x_i; \theta). $$

---

### **5. 分类任务中的具体形式**
#### **(1) 多分类任务（Softmax 输出）**
- 模型输出:经过Softmax的K维概率向量：

  $$ Q(y=k | x; \theta) = \frac{e^{z_k}}{\sum_{j=1}^K e^{z_j}}, \quad z_k = \text{模型输出的 logits}. $$

- 真实标签:one-hot编码$y_i \in \{0,1\}^K$，仅正确类别为1。

**极大似然函数**：  
对每个样本，仅保留真实类别对应的概率：

$$ \mathcal{L}(\theta) = \prod_{i=1}^N \prod_{k=1}^K Q(k | x_i; \theta)^{y_{i,k}}, $$

其中 $y_{i,k}$ 表示第i个样本是否属于类别k。

**负对数似然**：  

$$ \text{NLL} = -\sum_{i=1}^N \sum_{k=1}^K y_{i,k} \log Q(k | x_i; \theta). $$

这等价于 **交叉熵损失**（Cross-Entropy Loss）。

---

#### **(2) 二分类任务（Sigmoid 输出）**
- 模型输出：经过 Sigmoid 的标量概率：

  $$ Q(y=1 | x; \theta) = \sigma(z) = \frac{1}{1 + e^{-z}}, \quad z = \text{模型输出的 logit}. $$

- 真实标签：$y_i \in \{0, 1\}$。

**极大似然函数**：  
对每个样本，似然为伯努利分布：

$$ \mathcal{L}(\theta) = \prod_{i=1}^N Q(y=1 | x_i; \theta)^{y_i} \cdot \left(1 - Q(y=1 | x_i; \theta)\right)^{1 - y_i}. $$

**负对数似然**： 

$$ \text{NLL} = -\sum_{i=1}^N \left[ y_i \log Q(y=1 | x_i; \theta) + (1 - y_i) \log \left(1 - Q(y=1 | x_i; \theta)\right) \right]. $$

这等价于 **二元交叉熵损失**（Binary Cross-Entropy Loss）。

---

### **6. 总结**
- **极大似然函数**：在分类任务中定义为模型对真实标签的预测概率的乘积。
- **负对数似然**：等价于交叉熵损失，是分类任务的标准损失函数。
- **直观解释**：通过最大化模型对真实标签的预测概率，迫使模型输出与真实分布一致。